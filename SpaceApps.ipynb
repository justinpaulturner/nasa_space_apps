{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZUiqkxP6GNp"
   },
   "outputs": [],
   "source": [
    "#this is a test commit edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9ntygEoQ4Wbv"
   },
   "outputs": [],
   "source": [
    "# INSTALLATIONS\n",
    "\n",
    "# !pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vtG0UpHN4Wbz",
    "outputId": "4adac075-9fdb-46b9-fa7b-1fc77972e798"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Flatten\n",
    ")\n",
    "\n",
    "ia.seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3sbxFJ6x4Wb2"
   },
   "outputs": [],
   "source": [
    "# configuration variables\n",
    "input_size = 256\n",
    "n_channels = 3\n",
    "model_save_path = 'test_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(self, data_path,\n",
    "                 to_fit=True, batch_size=1, dim=(256, 256),\n",
    "                 n_channels=3, shuffle=True, augment=True):\n",
    "        'Initialization'\n",
    "        self.data_path = data_path\n",
    "        self.tif_list = []\n",
    "        self.mask_list = []\n",
    "        for filename in glob(f'{data_path}*.tif*'):\n",
    "            self.tif_list.append(filename)\n",
    "\n",
    "        self.to_fit = to_fit\n",
    "        self.augment = augment\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.tif_list) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.tif_list))\n",
    "        if self.shuffle is True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index *\n",
    "                               self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        tif_list_temp = [self.tif_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(tif_list_temp)\n",
    "\n",
    "        #  preprocess and augment data\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(tif_list_temp)\n",
    "\n",
    "            if self.augment:\n",
    "                seq = make_augmentations()\n",
    "                images_aug = list()\n",
    "                labels_aug = list()\n",
    "                for i in range(len(X)):\n",
    "                    image, label = seq(\n",
    "                        image=X[i].astype('float32'),\n",
    "                        segmentation_maps=np.expand_dims(\n",
    "                            y[i], 0).astype('uint8')\n",
    "                    )\n",
    "                    images_aug.append(image)\n",
    "                    labels_aug.append(label[0, :, :, :])\n",
    "\n",
    "                return np.array(images_aug), np.array(labels_aug)\n",
    "            else:\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                return X, y[:,:,:,0]\n",
    "\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def _generate_X(self, tif_list_temp):\n",
    "        'Generates data containing batch_size images'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # Store sample\n",
    "            X[i, ] = _load_tif_image(ID, self.dim)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _generate_y(self, tif_list_temp):\n",
    "        'Generates data containing batch_size masks'\n",
    "        y = np.empty((self.batch_size, *self.dim, 1), dtype='float32')\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tif_list_temp):\n",
    "            # replace tif/tiff with the _bitmap.png or .bmp, depending on the dataset\n",
    "            # to look for corresponding masks for the imput images\n",
    "            y[i, ] = _load_grayscale_image(ID.replace(\n",
    "                '.tiff', '_bitmap.png'), self.dim\n",
    "            )\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result\n",
    "\n",
    "\n",
    "def _load_grayscale_image(image_path, dim):\n",
    "    'Load grayscale image'\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img / 255\n",
    "\n",
    "    return np.expand_dims(cv2.resize(img, dim), -1)\n",
    "\n",
    "\n",
    "def _load_tif_image(image_path, dim):\n",
    "    'load tif image'\n",
    "\n",
    "    with rasterio.open(image_path, 'r') as data:\n",
    "        return cv2.resize(\n",
    "            np.moveaxis(data.read(), 0, -1), dim\n",
    "        )\n",
    "\n",
    "\n",
    "def sometimes(aug):\n",
    "    return iaa.Sometimes(0.5, aug)\n",
    "\n",
    "def make_augmentations():\n",
    "\n",
    "    return iaa.Sequential([\n",
    "        sometimes(iaa.CoarseDropout(0.1, size_percent=0.2)),\n",
    "        sometimes(\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                # scale images to 80-120% of their size,\n",
    "                # individually per axis\n",
    "                translate_percent={\n",
    "                    \"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                # translate by -20 to +20 percent (per axis)\n",
    "                # rotate by -45 to +45 degrees\n",
    "                rotate=(-10, 10),\n",
    "                shear=(-5, 5),  # shear by -16 to +16 degrees\n",
    "            ),\n",
    "        ),\n",
    "        sometimes(iaa.ElasticTransformation(alpha=10, sigma=1))\n",
    "    ],\n",
    "        random_order=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jared/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 24) 672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 24) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 24) 5208        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 24) 5208        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 24) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 24) 96          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 24) 96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 24) 96          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 24) 5208        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 24)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 24)   96          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 24)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 24)   96          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 24)   5208        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 24)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 24)   96          max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 24)   5208        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 24)   96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 24)   5208        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 24)   96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 24)   5208        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 48)   0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 48)   192         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 32)   13856       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 24)   6936        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 24)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 24) 5208        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 48) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 48) 192         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 32) 13856       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 24) 6936        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 24) 96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 24) 5208        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 48) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 48) 192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 32) 13856       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 24) 6936        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 1)  25          conv2d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 132,985\n",
      "Trainable params: 131,881\n",
      "Non-trainable params: 1,104\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "input_shape = (input_size, input_size, 3)\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "def bn_conv_relu(input, filters, bachnorm_momentum, **conv2d_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2D(filters, **conv2d_args)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bn_upconv_relu(input, filters, bachnorm_momentum, **conv2d_trans_args):\n",
    "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
    "    x = Conv2DTranspose(filters, **conv2d_trans_args)(x)\n",
    "    return x\n",
    "\n",
    "filters = 24\n",
    "upconv_filters = 32\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "activation = 'relu'\n",
    "strides = (1, 1)\n",
    "padding = 'same'\n",
    "kernel_initializer = 'he_normal'\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "conv2d_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': strides,\n",
    "    'padding': padding,\n",
    "    'kernel_initializer': kernel_initializer\n",
    "}\n",
    "\n",
    "conv2d_trans_args = {\n",
    "    'kernel_size': kernel_size,\n",
    "    'activation': activation,\n",
    "    'strides': (2, 2),\n",
    "    'padding': padding,\n",
    "}\n",
    "\n",
    "bachnorm_momentum = 0.01\n",
    "\n",
    "pool_size = (2, 2)\n",
    "pool_strides = (2, 2)\n",
    "pool_padding = 'valid'\n",
    "\n",
    "maxpool2d_args = {\n",
    "    'pool_size': pool_size,\n",
    "    'strides': pool_strides,\n",
    "    'padding': pool_padding,\n",
    "}\n",
    "\n",
    "x = Conv2D(filters, **conv2d_args)(inputs)\n",
    "c1 = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(c1, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "down_layers = []\n",
    "\n",
    "for l in range(num_layers):\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    down_layers.append(x)\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = MaxPooling2D(**maxpool2d_args)(x)\n",
    "\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n",
    "\n",
    "for conv in reversed(down_layers):\n",
    "    x = concatenate([x, conv])\n",
    "    x = bn_conv_relu(\n",
    "        x, upconv_filters, bachnorm_momentum, **conv2d_args\n",
    "    )\n",
    "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "    x = bn_upconv_relu(\n",
    "        x, filters, bachnorm_momentum, **conv2d_trans_args\n",
    "    )\n",
    "\n",
    "x = concatenate([x, c1])\n",
    "x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n",
    "x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
    "\n",
    "outputs = Conv2D(\n",
    "    1,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    activation=output_activation,\n",
    "    padding='valid')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "\n",
    "pl = PlotLearning()\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=20,\n",
    "                  verbose=1, mode=\"auto\"),\n",
    "    ModelCheckpoint(filepath=model_save_path,\n",
    "                    verbose=1, save_best_only=True),\n",
    "    pl,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jared/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "                learning_rate=0.0001,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=1e-07,\n",
    "                amsgrad=False,\n",
    "            ),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 352 files [00:02, 167.51 files/s]\n"
     ]
    }
   ],
   "source": [
    "#Data splits\n",
    "# import splitfolders\n",
    "\n",
    "# splitfolders.ratio(\"data/input/\", output=\"data/output/\", seed=1337, ratio=(.8, .2), group_prefix=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = UnetGenerator('data/output/train/class1', batch_size=4)\n",
    "val_generator = UnetGenerator('data/output/val/class1', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=13,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SpaceApps.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
